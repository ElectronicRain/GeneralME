#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FluidCNN v6 Main Training Script
Based on FluidCNN v5, adding top-16-row feature enhancement parallel branch

Architecture v6:
Input (H, W, 3)
  â”œâ”€ Parallel Branch 1: Top16RowModule â†’ Extract top 16 rows â†’ 1xN Conv â†’ MLP â†’ 128-dim feature
  â””â”€ Parallel Branch 2: Multi-branch Residual + SE Attention â†’ (H, W, 96)
       â””â”€ Residual + Downsample â†’ (H/2, W/2, 96)
            â””â”€ Residual â†’ (H/2, W/2, 128)
                 â””â”€ Conv Pool â†’ (H/4, W/4, 128)
                      â””â”€ Residual + Downsample â†’ (H/8, W/8, 128)
                           â””â”€ Residual â†’ (H/8, W/8, 256)
                                â””â”€ Residual + Downsample â†’ (H/16, W/16, 256)
                                     â””â”€ Residual â†’ (H/16, W/16, 512)
                                          â””â”€ GlobalAvgPool â†’ 512
                                               â””â”€ Feature Fusion: 512-dim + 128-dim â†’ 640-dim
                                                    â””â”€ Dense â†’ 256â†’128â†’8

Core Features:
âœ“ Parallel Top16RowModule for top 16 rows
âœ“ 1xN convolution kernel (configurable N)
âœ“ MLP feature scaling
âœ“ Weighted feature fusion (main branch 512-dim + parallel branch 128-dim)
âœ“ Fixed random seed for reproducibility
âœ“ Residual connections (ResNet-style)
âœ“ SE channel attention mechanism
âœ“ GELU activation function
âœ“ Enhanced classifier (3-layer FC + BN + Dropout)
âœ“ AdamW optimizer + Cosine Annealing scheduler
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support
from datetime import datetime
import sys
from pathlib import Path
import time
import warnings
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns

# Import custom modules
from model import FluidCNNEnhancedV6
from data_loader import MultiSizeMeshDataset, pad_collate
from trainer import FluidCNNTrainer
from tsne_analyzer import TSNEAnalyzer
from utils import (
    setup_logging,
    cleanup_logging,
    plot_training_history,
    print_model_summary,
    format_time,
    print_separator
)


def main():
    """Main training workflow"""
    # ==================== Initialize logging ====================
    print_separator()
    print("FluidCNN v6 - Top-16 Row Feature Enhancement Parallel Branch Version")
    print("=" * 60)
    print("Core Features: Parallel Branch | 1xN Convolution | Weighted Fusion | Fixed Seed")
    print("=" * 60)

    now = datetime.now()

    # Create temporary run directory
    temp_dir_suffix = now.strftime('%m%d_%H%M%S')
    temp_run_dir = Path("logs") / f"pending_{temp_dir_suffix}"
    temp_run_dir.mkdir(parents=True, exist_ok=True)

    log_filename, original_stdout, log_file = setup_logging(temp_run_dir)

    final_test_acc = None

    try:
        # ==================== Training configuration ====================
        # v6 configuration: Add parallel branch, enhance feature extraction
        BATCH_SIZE = 32
        EPOCHS = 200
        LEARNING_RATE = 3e-4
        WEIGHT_DECAY = 1e-4
        EARLY_STOPPING_PATIENCE = 60

        # Model configuration
        BRANCH_CHANNELS = 32  # Multi-branch convolution channels
        DROPOUT_RATE = 0.3    # Dropout probability

        # v6 specific configuration: Top-16 row module parameters
        CONV_KERNEL_SIZE = 10  # 1xN convolution kernel size N (adjustable)
        TOP16_HIDDEN_DIM = 64  # Top-16 row module MLP hidden layer dimension
        FUSION_METHOD = 'weighted_sum'  # Fusion method: 'weighted_sum' or 'concat'
        RANDOM_SEED = 42  # Fixed random seed

        # Feature channel selection (use all 8 feature channels)
        FEATURES_TO_USE = [0, 1, 2, 3, 4, 5, 6, 7]

        # T-SNE analysis configuration
        TSNE_ENABLED = True
        TSNE_EPOCHS = [5, 10, 15, 20, 25, 30, 35, 40, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
        TSNE_MAX_SAMPLES = 10240
        TSNE_PERPLEXITY = 30

        print(f"\nTraining Configuration:")
        print(f"   Batch size: {BATCH_SIZE}")
        print(f"   Epochs: {EPOCHS}")
        print(f"   Learning rate: {LEARNING_RATE}")
        print(f"   Optimizer: AdamW")
        print(f"   Weight decay: {WEIGHT_DECAY}")
        print(f"   Scheduler: CosineAnnealingWarmRestarts")
        print(f"   Early stopping patience: {EARLY_STOPPING_PATIENCE}")
        print(f"   Feature indices: {FEATURES_TO_USE} (Total: {len(FEATURES_TO_USE)} features)")
        print(f"\nModel Configuration:")
        print(f"   Branch channels: {BRANCH_CHANNELS}")
        print(f"   Dropout rate: {DROPOUT_RATE}")
        print(f"   Main branch convolution kernel: 3x10 (Rectangular convolution)")
        print(f"\nv6 Specific Configuration:")
        print(f"   1xN convolution kernel size: {CONV_KERNEL_SIZE}")
        print(f"   Top16 module hidden dimension: {TOP16_HIDDEN_DIM}")
        print(f"   Fusion method: {FUSION_METHOD}")
        print(f"   Random seed: {RANDOM_SEED}")
        print(f"\nT-SNE Analysis Configuration:")
        print(f"   Enable T-SNE: {TSNE_ENABLED}")
        print(f"   Analysis epochs: {TSNE_EPOCHS}")
        print(f"   Max samples: {TSNE_MAX_SAMPLES}")
        print(f"   Perplexity: {TSNE_PERPLEXITY}")

        feature_str = "".join(map(str, FEATURES_TO_USE))
        model_filename = temp_run_dir / f"{feature_str}_best_cnn_v6.pt"

        # ==================== Load dataset ====================
        print("\nLoading dataset...")
        try:
            dataset = MultiSizeMeshDataset("../cnn_input_data", feature_indices=FEATURES_TO_USE)
            print(f"Dataset loaded successfully!")
            print(f"   Total samples: {len(dataset)}")
            print(f"   Original feature channels: {dataset.num_input_channels()}")
            print(f"   Model input channels: {dataset.num_input_channels() + 3} (including mask and coordinates)")
        except Exception as e:
            print(f"Dataset loading failed: {e}")
            import traceback
            traceback.print_exc()
            raise

        # ==================== Split dataset ====================
        print("\nSplitting dataset...")
        indices = list(range(len(dataset)))

        if len(indices) < 3:
            raise RuntimeError(f"Dataset too small ({len(indices)} samples), cannot split")

        # 8 sizes for training, 1 for testing, 1 for validation
        # 7:3 split training and (validation + testing), then split equally -> 7:1.5:1.5
        train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42)
        val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)

        train_dataset = torch.utils.data.Subset(dataset, train_idx)
        val_dataset = torch.utils.data.Subset(dataset, val_idx)
        test_dataset = torch.utils.data.Subset(dataset, test_idx)

        print(f"   Training set: {len(train_dataset)} samples ({len(train_dataset)/len(dataset)*100:.1f}%)")
        print(f"   Validation set: {len(val_dataset)} samples ({len(val_dataset)/len(dataset)*100:.1f}%)")
        print(f"   Test set: {len(test_dataset)} samples ({len(test_dataset)/len(dataset)*100:.1f}%)")

        if len(train_dataset) == 0:
            raise RuntimeError("Training set is empty, cannot train")

        # ==================== Create DataLoader ====================
        print("\n[CONFIG] Creating DataLoader...")
        num_workers = 0
        train_loader = DataLoader(
            train_dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            collate_fn=pad_collate,
            num_workers=num_workers
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=BATCH_SIZE,
            shuffle=False,
            collate_fn=pad_collate,
            num_workers=num_workers
        )
        test_loader = DataLoader(
            test_dataset,
            batch_size=BATCH_SIZE,
            shuffle=False,
            collate_fn=pad_collate,
            num_workers=num_workers
        )
        print("[OK] DataLoader created successfully!")

        # ==================== Initialize model ====================
        print("\n[INIT] Initializing FluidCNN v6 Top-16 Row Feature Enhancement Parallel Branch Version...")
        model_input_channels = dataset.num_input_channels() + 3  # mask + coord_x + coord_y

        model = FluidCNNEnhancedV6(
            input_channels=model_input_channels,
            num_classes=8,
            branch_channels=BRANCH_CHANNELS,
            dropout_rate=DROPOUT_RATE,
            conv_kernel_size=CONV_KERNEL_SIZE,
            top16_hidden_dim=TOP16_HIDDEN_DIM,
            fusion_method=FUSION_METHOD,
            seed=RANDOM_SEED
        )

        # Print model summary
        print_model_summary(model, (model_input_channels, 64, 64))

        # Display model information
        model_info = model.get_model_info()
        print(f"\n[INFO] Model Information:")
        print(f"   Name: {model_info['model_name']}")
        print(f"   Input channels: {model_info['input_channels']}")
        print(f"   Number of classes: {model_info['num_classes']}")
        print(f"   1xN convolution kernel size: {model_info['conv_kernel_size']}")
        print(f"   Top16 hidden dimension: {model_info['top16_hidden_dim']}")
        print(f"   Fusion method: {model_info['fusion_method']}")
        print(f"   Key features:")
        for feature in model_info.get("key_features", []):
            print(f"     - {feature}")

        # ==================== Initialize optimizer and scheduler ====================
        print("\n[CONFIG] Initializing optimizer and scheduler...")
        optimizer = optim.AdamW(
            model.parameters(),
            lr=LEARNING_RATE,
            weight_decay=WEIGHT_DECAY,
            betas=(0.9, 0.999)
        )
        criterion = nn.CrossEntropyLoss()

        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer,
            T_0=10,
            T_mult=2,
            eta_min=1e-6
        )

        trainer = FluidCNNTrainer(model)
        print("[OK] Model and optimizer initialized successfully!")

        # Initialize T-SNE analyzer
        tsne_dir = temp_run_dir / "tsne_analysis"
        tsne_analyzer = TSNEAnalyzer(save_dir=str(tsne_dir))
        print(f"[OK] T-SNE analyzer initialized, save directory: {tsne_dir}")

        # ==================== Training loop ====================
        best_accuracy = 0.0
        best_val_report = {}
        train_losses, val_losses = [], []
        train_accuracies, val_accuracies = [], []

        epochs_no_improve = 0

        print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        print_separator()

        # æµ‹è¯•æ•°æ®åŠ è½½å’Œæ¨¡å‹å‰å‘ä¼ æ’­
        print("ğŸ” æµ‹è¯•æ•°æ®åŠ è½½å’Œæ¨¡å‹å‰å‘ä¼ æ’­...")
        test_batch = next(iter(train_loader))
        test_inputs, test_labels = test_batch
        test_inputs = test_inputs.to(trainer.device)
        test_outputs = trainer.model(test_inputs)
        print(f"   âœ… æµ‹è¯•æˆåŠŸï¼")
        print(f"   Batch å½¢çŠ¶: {test_inputs.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {test_outputs.shape}")

        # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        total_start_time = time.time()

        for epoch in range(EPOCHS):
            print(f"\nğŸ“… Epoch {epoch + 1:02d}/{EPOCHS}")

            try:
                train_loss, train_acc = trainer.train_one_epoch(train_loader, optimizer, criterion)

                if len(val_dataset) > 0:
                    val_loss, val_acc, val_report = trainer.evaluate(val_loader, criterion)
                else:
                    val_loss, val_acc, val_report = 0.0, 0.0, {}
                    print("   âš ï¸  è·³è¿‡éªŒè¯ï¼ˆéªŒè¯é›†ä¸ºç©ºï¼‰")

            except KeyboardInterrupt:
                print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
                break

            except Exception as e:
                print(f"âŒ Epoch {epoch + 1} è®­ç»ƒå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                print("   ç»§ç»­ä¸‹ä¸€ä¸ª epoch...")
                continue

            # è®°å½•æŒ‡æ ‡
            train_losses.append(train_loss)
            val_losses.append(val_loss)
            train_accuracies.append(train_acc)
            val_accuracies.append(val_acc)

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()

            print(f"   è®­ç»ƒ Loss: {train_loss:.4f} | è®­ç»ƒ Acc: {train_acc:.4f}")
            print(f"   éªŒè¯ Loss: {val_loss:.4f} | éªŒè¯ Acc: {val_acc:.4f}")

            # æ˜¾ç¤ºå½“å‰å­¦ä¹ ç‡
            current_lr = optimizer.param_groups[0]['lr']
            print(f"   å­¦ä¹ ç‡: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_accuracy:
                best_accuracy = val_acc
                epochs_no_improve = 0
                best_val_report = val_report
                torch.save(model.state_dict(), model_filename)
                print(f"ğŸ’¾ å·²ä¿å­˜æœ€ä½³æ¨¡å‹è‡³ {model_filename}")

                # æ˜¾ç¤ºå„ç±»åˆ«å‡†ç¡®ç‡
                print("   ğŸ“ˆ æœ€ä½³éªŒè¯é›†å„ç±»åˆ«å‡†ç¡®ç‡:")
                if best_val_report:
                    for class_name, metrics in best_val_report.items():
                        if class_name.startswith("Label"):
                            recall = metrics.get('recall', 0.0)
                            print(f"      - {class_name}: {recall:.2%}")
            else:
                epochs_no_improve += 1
                print(f"   (!) éªŒè¯å‡†ç¡®ç‡æœªæå‡, æ—©åœè®¡æ•°: {epochs_no_improve}/{EARLY_STOPPING_PATIENCE}")
                if epochs_no_improve >= EARLY_STOPPING_PATIENCE:
                    print(f"\nğŸ›‘ è¿ç»­ {EARLY_STOPPING_PATIENCE} ä¸ª epochs éªŒè¯å‡†ç¡®ç‡æœªæå‡, è§¦å‘æ—©åœã€‚")
                    break

            # æ¯5è½®ä¿å­˜æ¨¡å‹å’Œæ··æ·†çŸ©é˜µ
            if (epoch + 1) % 5 == 0:
                print(f"\nğŸ“¦ ä¿å­˜ç¬¬ {epoch + 1} è½®æ¨¡å‹å’Œæ··æ·†çŸ©é˜µ...")
                checkpoint_filename = temp_run_dir / f"checkpoint_epoch_{epoch+1:03d}.pt"
                torch.save(model.state_dict(), checkpoint_filename)
                print(f"   ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {checkpoint_filename}")

                # è®¡ç®—æ··æ·†çŸ©é˜µ
                print(f"   ğŸ“Š è®¡ç®—ç¬¬ {epoch + 1} è½®æ··æ·†çŸ©é˜µ...")
                try:
                    cm_output_dir = temp_run_dir / f"confusion_matrix_epoch_{epoch+1:03d}"
                    cm_output_dir.mkdir(exist_ok=True)

                    # åœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ··æ·†çŸ©é˜µ
                    all_preds = []
                    all_labels = []

                    model.eval()
                    with torch.no_grad():
                        for batch_idx, (inputs, labels) in enumerate(val_loader):
                            inputs, labels = inputs.to(trainer.device), labels.to(trainer.device)
                            outputs = model(inputs)
                            preds = outputs.argmax(1).cpu().numpy()
                            all_preds.extend(preds)
                            all_labels.extend(labels.cpu().numpy())

                    all_preds = np.array(all_preds)
                    all_labels = np.array(all_labels)

                    # è®¡ç®—æ··æ·†çŸ©é˜µ
                    cm = confusion_matrix(all_labels, all_preds, labels=range(8))
                    class_names = [f"Label {i}" for i in range(8)]

                    # ä¿å­˜æ··æ·†çŸ©é˜µæ•°æ®
                    cm_file = cm_output_dir / "confusion_matrix_data.csv"
                    np.savetxt(cm_file, cm, delimiter=',', fmt='%d')

                    # ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
                    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

                    plt.figure(figsize=(12, 10))

                    cm_labels = np.empty_like(cm, dtype=object)
                    for i in range(cm.shape[0]):
                        for j in range(cm.shape[1]):
                            count = cm[i, j]
                            percent = cm_percent[i, j]
                            if count > 0:
                                cm_labels[i, j] = f'{count}\n({percent:.1f}%)'
                            else:
                                cm_labels[i, j] = f'0\n(0.0%)'

                    sns.heatmap(cm, annot=cm_labels, fmt='', cmap='Blues',
                                xticklabels=class_names, yticklabels=class_names,
                                cbar_kws={'label': 'Count'}, square=True, linewidths=0.5)

                    plt.title(f'FluidCNN v6 - Confusion Matrix (Epoch {epoch+1}, Validation Set)',
                              fontsize=16, fontweight='bold', pad=20)
                    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
                    plt.ylabel('True Label', fontsize=12, fontweight='bold')
                    plt.tight_layout()

                    cm_plot_path = cm_output_dir / "confusion_matrix_heatmap.png"
                    plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')
                    plt.close()  # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜

                    # è®¡ç®—æŒ‡æ ‡
                    precision, recall, f1, support = precision_recall_fscore_support(
                        all_labels, all_preds, labels=range(8), average=None, zero_division=0
                    )

                    # ä¿å­˜æŠ¥å‘Š
                    report_file = cm_output_dir / "confusion_matrix_report.txt"
                    with open(report_file, 'w', encoding='utf-8') as f:
                        f.write(f"FluidCNN v6 æ··æ·†çŸ©é˜µåˆ†ææŠ¥å‘Š - ç¬¬ {epoch+1} è½®\n")
                        f.write("=" * 80 + "\n\n")
                        f.write(f"æ¨¡å‹æ–‡ä»¶: {checkpoint_filename}\n")
                        f.write(f"éªŒè¯æ ·æœ¬æ•°: {len(all_labels)}\n")
                        f.write(f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f} ({val_acc*100:.2f}%)\n\n")

                        f.write("æ··æ·†çŸ©é˜µ:\n")
                        f.write("-" * 80 + "\n")
                        for i in range(8):
                            f.write(f"T{i}: ")
                            for j in range(8):
                                f.write(f"{cm[i, j]:4d} ")
                            f.write("\n")

                        f.write("\nå„ç±»åˆ«æŒ‡æ ‡:\n")
                        f.write("-" * 80 + "\n")
                        f.write(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'æ”¯æŒæ•°':<10}\n")
                        f.write("-" * 80 + "\n")
                        for i in range(8):
                            f.write(f"{class_names[i]:<12} {precision[i]:<10.4f} {recall[i]:<10.4f} "
                                  f"{f1[i]:<10.4f} {support[i]:<10}\n")

                    print(f"   âœ… ç¬¬ {epoch + 1} è½®æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {cm_output_dir}")
                    print(f"      - çƒ­åŠ›å›¾: {cm_plot_path}")
                    print(f"      - æ•°æ®: {cm_file}")
                    print(f"      - æŠ¥å‘Š: {report_file}")

                except Exception as e:
                    print(f"   âš ï¸  ç¬¬ {epoch + 1} è½®æ··æ·†çŸ©é˜µè®¡ç®—å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()

            # T-SNEåˆ†æ
            if TSNE_ENABLED and (epoch + 1) in TSNE_EPOCHS:
                print(f"\nğŸ”¬ æ‰§è¡Œ T-SNE åˆ†æ (Epoch {epoch + 1})...")
                try:
                    # ä½¿ç”¨éªŒè¯é›†è¿›è¡ŒT-SNEåˆ†æ
                    if len(val_dataset) > 0:
                        features, labels, predictions = trainer.collect_features(
                            val_loader, max_samples=TSNE_MAX_SAMPLES
                        )

                        # æ·»åŠ åˆ°åˆ†æå™¨
                        tsne_analyzer.epoch_features[epoch + 1] = features
                        tsne_analyzer.epoch_labels[epoch + 1] = labels
                        tsne_analyzer.epoch_predictions[epoch + 1] = predictions

                        # è¿è¡ŒT-SNE
                        tsne_result = tsne_analyzer.run_tsne(
                            epoch + 1,
                            perplexity=TSNE_PERPLEXITY
                        )

                        if tsne_result:
                            # ç”Ÿæˆå¹¶æ˜¾ç¤ºæŠ¥å‘Š
                            print("\n" + tsne_analyzer.generate_report(epoch + 1))

                            # ç»˜åˆ¶å¯è§†åŒ–
                            tsne_analyzer.plot_tsne(epoch + 1, save=True, show=False)

                            # ä¿å­˜åˆ†æç»“æœ
                            tsne_analyzer.save_analysis(epoch + 1)

                            print(f"âœ… T-SNE åˆ†æå®Œæˆ")
                        else:
                            print(f"âš ï¸  T-SNE åˆ†æå¤±è´¥")
                    else:
                        print(f"   è·³è¿‡T-SNEï¼ˆéªŒè¯é›†ä¸ºç©ºï¼‰")

                except Exception as e:
                    print(f"   âš ï¸  T-SNE åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()

        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        total_time = time.time() - total_start_time
        print(f"\nâ±ï¸  æ€»è®­ç»ƒæ—¶é—´: {format_time(total_time)}")

        # ==================== åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆåˆ†æ ====================
        print("\nğŸ§ª åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•...")
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=FutureWarning)
            model.load_state_dict(torch.load(model_filename, map_location=trainer.device, weights_only=False))

        # ==================== æœ€ç»ˆT-SNEåˆ†æï¼ˆä½¿ç”¨æµ‹è¯•é›†ï¼‰ ====================
        if TSNE_ENABLED and len(test_dataset) > 0:
            print(f"\nğŸ”¬ æ‰§è¡Œæœ€ç»ˆ T-SNE åˆ†æï¼ˆä½¿ç”¨æµ‹è¯•é›†ï¼‰...")
            try:
                final_epoch = EPOCHS

                # æ”¶é›†æµ‹è¯•é›†ç‰¹å¾
                features, labels, predictions = trainer.collect_features(
                    test_loader, max_samples=TSNE_MAX_SAMPLES
                )

                # æ·»åŠ åˆ°åˆ†æå™¨
                tsne_analyzer.epoch_features[final_epoch] = features
                tsne_analyzer.epoch_labels[final_epoch] = labels
                tsne_analyzer.epoch_predictions[final_epoch] = predictions

                # è¿è¡ŒT-SNE
                tsne_result = tsne_analyzer.run_tsne(
                    final_epoch,
                    perplexity=TSNE_PERPLEXITY
                )

                if tsne_result:
                    # ç”Ÿæˆå¹¶æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
                    print("\n" + "="*80)
                    print("æœ€ç»ˆ T-SNE åˆ†ææŠ¥å‘Šï¼ˆæµ‹è¯•é›†ï¼‰")
                    print("="*80)
                    print(tsne_analyzer.generate_report(final_epoch))

                    # ç»˜åˆ¶å¯è§†åŒ–
                    tsne_analyzer.plot_tsne(final_epoch, save=True, show=False)

                    # ä¿å­˜åˆ†æç»“æœ
                    tsne_analyzer.save_analysis(final_epoch)

                    print(f"âœ… æœ€ç»ˆ T-SNE åˆ†æå®Œæˆ")
                else:
                    print(f"âš ï¸  æœ€ç»ˆ T-SNE åˆ†æå¤±è´¥")

            except Exception as e:
                print(f"   âš ï¸  æœ€ç»ˆ T-SNE åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

        # ==================== æµ‹è¯•æœ€ä½³æ¨¡å‹ ====================
        print("\nğŸ§ª æµ‹è¯•æœ€ä½³æ¨¡å‹...")

        test_loss, test_acc, test_report = trainer.evaluate(test_loader, criterion)
        final_test_acc = test_acc

        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_accuracy:.4f}")

        # æ˜¾ç¤ºæœ€ç»ˆæ€§èƒ½è¯„ä¼°
        print("\nğŸ“Š æœ€ç»ˆæ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        print("   ğŸ“ˆ æœ€ä½³éªŒè¯é›†å„ç±»åˆ«å‡†ç¡®ç‡:")
        if best_val_report:
            for class_name, metrics in best_val_report.items():
                if class_name.startswith("Label"):
                    recall = metrics.get('recall', 0.0)
                    print(f"      - {class_name}: {recall:.2%}")

        print("   ğŸ“ˆ æµ‹è¯•é›†å„ç±»åˆ«å‡†ç¡®ç‡:")
        if test_report:
            for class_name, metrics in test_report.items():
                if class_name.startswith("Label"):
                    recall = metrics.get('recall', 0.0)
                    print(f"      - {class_name}: {recall:.2%}")

        # ==================== æ··æ·†çŸ©é˜µåˆ†æ ====================
        print("\nğŸ“Š æ‰§è¡Œæ··æ·†çŸ©é˜µåˆ†æ...")
        try:
            import os

            # åˆ›å»ºæ··æ·†çŸ©é˜µè¾“å‡ºç›®å½•
            cm_output_dir = temp_run_dir / "confusion_matrix_analysis"
            cm_output_dir.mkdir(exist_ok=True)

            # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
            print("   ğŸ” æ”¶é›†é¢„æµ‹ç»“æœ...")
            all_preds = []
            all_labels = []

            model.eval()
            with torch.no_grad():
                for batch_idx, (inputs, labels) in enumerate(test_loader):
                    inputs, labels = inputs.to(trainer.device), labels.to(trainer.device)
                    outputs = model(inputs)
                    preds = outputs.argmax(1).cpu().numpy()

                    all_preds.extend(preds)
                    all_labels.extend(labels.cpu().numpy())

            all_preds = np.array(all_preds)
            all_labels = np.array(all_labels)

            print(f"   âœ… æ”¶é›†å®Œæˆ! æ€»æ ·æœ¬æ•°: {len(all_labels)}")

            # è®¡ç®—æ··æ·†çŸ©é˜µ
            cm = confusion_matrix(all_labels, all_preds, labels=range(8))

            # ç±»åˆ«åç§°
            class_names = [f"Label {i}" for i in range(8)]

            # æ‰“å°æ··æ·†çŸ©é˜µ
            print("\n" + "=" * 80)
            print("ğŸ“Š æ··æ·†çŸ©é˜µ (æ•°å€¼)")
            print("=" * 80)
            print("è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾")
            print("-" * 80)
            print(f"{'ç±»åˆ«':<12}", end="")
            for i in range(8):
                print(f"{f'P{i}':<8}", end="")
            print()
            print("-" * 80)

            for i in range(8):
                print(f"{f'T{i}':<12}", end="")
                for j in range(8):
                    print(f"{cm[i, j]:<8}", end="")
                print()

            # ä¿å­˜åŸå§‹æ··æ·†çŸ©é˜µæ•°æ®
            cm_file = cm_output_dir / "confusion_matrix_data.csv"
            np.savetxt(cm_file, cm, delimiter=',', fmt='%d')
            print(f"âœ… æ··æ·†çŸ©é˜µåŸå§‹æ•°æ®å·²ä¿å­˜è‡³: {cm_file}")

            # ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
            print("\nğŸ¨ ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾...")

            # è®¡ç®—ç™¾åˆ†æ¯”
            cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

            # è®¾ç½®å›¾è¡¨å¤§å°
            plt.figure(figsize=(12, 10))

            # åˆ›å»ºæ ‡ç­¾ï¼ˆæ˜¾ç¤ºæ•°é‡å’Œç™¾åˆ†æ¯”ï¼‰
            cm_labels = np.empty_like(cm, dtype=object)
            for i in range(cm.shape[0]):
                for j in range(cm.shape[1]):
                    count = cm[i, j]
                    percent = cm_percent[i, j]
                    if count > 0:
                        cm_labels[i, j] = f'{count}\n({percent:.1f}%)'
                    else:
                        cm_labels[i, j] = f'0\n(0.0%)'

            # ç»˜åˆ¶çƒ­åŠ›å›¾
            sns.heatmap(cm, annot=cm_labels, fmt='', cmap='Blues',
                        xticklabels=class_names, yticklabels=class_names,
                        cbar_kws={'label': 'Count'}, square=True, linewidths=0.5)

            plt.title('FluidCNN v6 - Confusion Matrix (Test Set)', fontsize=16, fontweight='bold', pad=20)
            plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
            plt.ylabel('True Label', fontsize=12, fontweight='bold')

            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            cm_plot_path = cm_output_dir / "confusion_matrix_heatmap.png"
            plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾å·²ä¿å­˜è‡³: {cm_plot_path}")

            # è®¡ç®—å„ç±»åˆ«æŒ‡æ ‡
            precision, recall, f1, support = precision_recall_fscore_support(
                all_labels, all_preds, labels=range(8), average=None, zero_division=0
            )

            # åˆ†æç»“æœ
            print("\nğŸ“ˆ å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
            print("-" * 80)
            print(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'æ”¯æŒæ•°':<10}")
            print("-" * 80)

            for i in range(8):
                print(f"{class_names[i]:<12} {precision[i]:<10.4f} {recall[i]:<10.4f} "
                      f"{f1[i]:<10.4f} {support[i]:<10}")

            # åˆ†ææ··æ·†æƒ…å†µ
            print("\nğŸ” åˆ†ç±»é”™è¯¯åˆ†æ:")
            print("-" * 80)

            for i in range(8):
                class_name = class_names[i]
                true_positives = cm[i, i]
                false_positives = cm[:, i].sum() - true_positives
                false_negatives = cm[i, :].sum() - true_positives

                # æ‰¾å‡ºæœ€å®¹æ˜“è¢«è¯¯åˆ†ç±»ä¸ºè¯¥ç±»åˆ«çš„å…¶ä»–ç±»åˆ«
                misclassified_to = []
                for j in range(8):
                    if i != j and cm[j, i] > 0:
                        misclassified_to.append((class_names[j], cm[j, i]))

                # æ‰¾å‡ºè¯¥ç±»åˆ«æœ€å®¹æ˜“è¢«è¯¯åˆ†ç±»æˆçš„å…¶ä»–ç±»åˆ«
                misclassified_from = []
                for j in range(8):
                    if i != j and cm[i, j] > 0:
                        misclassified_from.append((class_names[j], cm[i, j]))

                print(f"\n{class_name}:")
                print(f"  âœ“ æ­£ç¡®åˆ†ç±»: {true_positives}")
                print(f"  âœ— è¢«å…¶ä»–ç±»åˆ«è¯¯åˆ†ç±»ä¸ºè¯¥ç±»åˆ«: {false_positives}")

                if misclassified_to:
                    misclassified_to.sort(key=lambda x: x[1], reverse=True)
                    print(f"    ä¸»è¦è¯¯åˆ†ç±»æ¥æº: {', '.join([f'{name}({count})' for name, count in misclassified_to[:3]])}")

                if misclassified_from:
                    misclassified_from.sort(key=lambda x: x[1], reverse=True)
                    print(f"  âœ— è¢«è¯¥ç±»åˆ«è¯¯åˆ†ç±»ä¸ºå…¶ä»–ç±»åˆ«: {false_negatives}")
                    print(f"    ä¸»è¦è¯¯åˆ†ç±»ç›®æ ‡: {', '.join([f'{name}({count})' for name, count in misclassified_from[:3]])}")

            # ä¿å­˜è¯¦ç»†åˆ†ææŠ¥å‘Š
            report_file = cm_output_dir / "confusion_matrix_analysis_report.txt"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("FluidCNN v6 æ··æ·†çŸ©é˜µåˆ†ææŠ¥å‘Š\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"æ¨¡å‹æ–‡ä»¶: {model_filename}\n")
                f.write(f"æµ‹è¯•æ ·æœ¬æ•°: {len(all_labels)}\n")
                f.write(f"æ€»ä½“å‡†ç¡®ç‡: {final_test_acc:.4f} ({final_test_acc*100:.2f}%)\n\n")

                f.write("æ··æ·†çŸ©é˜µ:\n")
                f.write("-" * 80 + "\n")
                f.write("è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾\n")
                f.write("-" * 80 + "\n")
                for i in range(8):
                    f.write(f"T{i}: ")
                    for j in range(8):
                        f.write(f"{cm[i, j]:4d} ")
                    f.write("\n")

                f.write("\nå„ç±»åˆ«æŒ‡æ ‡:\n")
                f.write("-" * 80 + "\n")
                f.write(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'æ”¯æŒæ•°':<10}\n")
                f.write("-" * 80 + "\n")
                for i in range(8):
                    f.write(f"{class_names[i]:<12} {precision[i]:<10.4f} {recall[i]:<10.4f} "
                          f"{f1[i]:<10.4f} {support[i]:<10}\n")

            print(f"\nâœ… æ··æ·†çŸ©é˜µè¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
            print("=" * 80)
            print(f"ğŸ“ æ··æ·†çŸ©é˜µåˆ†æç»“æœä¿å­˜åœ¨: {cm_output_dir}")
            print(f"   - æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾: {cm_plot_path}")
            print(f"   - æ··æ·†çŸ©é˜µæ•°æ®: {cm_file}")
            print(f"   - è¯¦ç»†åˆ†ææŠ¥å‘Š: {report_file}")
            print("=" * 80)

        except Exception as e:
            print(f"   âš ï¸  æ··æ·†çŸ©é˜µåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

        # ==================== ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ====================
        print("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿...")
        plot_filename = temp_run_dir / "training_history.png"
        plot_training_history(
            train_losses, val_losses,
            train_accuracies, val_accuracies,
            plot_filename
        )

        print("\nâœ… FluidCNN v6 é¡¶éƒ¨16è¡Œç‰¹å¾å¢å¼ºå¹¶è¡Œåˆ†æ”¯ç‰ˆæœ¬è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ‰ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_test_acc:.4f}")

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

    finally:
        # ==================== æ¸…ç†å’Œä¿å­˜æ—¥å¿— ====================
        print(f"\nğŸ“ è®­ç»ƒæ—¥å¿—å’Œç»“æœå¤„ç†...")
        sys.stdout = original_stdout
        log_file.close()

        # æ¸…ç†æ—¥å¿—å¹¶é‡å‘½åæ–‡ä»¶
        cleanup_logging(original_stdout, log_file, temp_run_dir, final_test_acc)


if __name__ == "__main__":
    main()
